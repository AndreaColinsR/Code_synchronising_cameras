{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502e4a8f-1044-4254-b8ea-a5618b72d830",
   "metadata": {},
   "source": [
    "# Calibrate single camera\n",
    "\n",
    "The aim of this calibration is to:\n",
    "1. Assess the distortion of the cameras\n",
    "2. function between X,Y,Z coordinates of the world and X,Y coordinates of the frame\n",
    "\n",
    "## Plan\n",
    "1. Open the video recorded with a camera\n",
    "2. Detect corners of the chessboard\n",
    "4. Calibrate and return points\n",
    "5. Join the calibration info from previous steps and perform stereo calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8a078e-a168-4d2e-9bfc-8591de32d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import DLT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c983477-f91f-4784-8262-dd8cc526bebd",
   "metadata": {},
   "source": [
    "## 1. Define function to calibrate single cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3ddda3-a94c-48cb-8a32-8752a1cc9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_both_cameras(VideoNameA,VideoNameB):\n",
    "\n",
    "    capA = cv.VideoCapture(VideoNameA)\n",
    "    capB = cv.VideoCapture(VideoNameB)\n",
    "    \n",
    "    find_flags = cv.CALIB_CB_ADAPTIVE_THRESH + cv.CALIB_CB_NORMALIZE_IMAGE\n",
    "    world_scaling = 30. #change this to the real world square size.\n",
    "\n",
    "    # termination criteria\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 50, 0.001)\n",
    " \n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*8,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:8,0:6].T.reshape(-1,2)\n",
    "    objp = world_scaling* objp\n",
    "     \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpointsA = [] # 2d points in image plane.\n",
    "    imgpointsB = [] # 2d points in image plane.\n",
    "\n",
    "    counter = 1\n",
    "    \n",
    "    while(capA.isOpened()):\n",
    "        retA, frameA = capA.read()\n",
    "        retB, frameB = capB.read()\n",
    "        counter = counter +1\n",
    "        if retA == True and retB == True and np.mod(counter,4)==0:\n",
    "            greyFrameA = cv.cvtColor(frameA, cv.COLOR_BGR2GRAY) \n",
    "            greyFrameB = cv.cvtColor(frameB, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Find the chess board corners\n",
    "            retA1, cornersA = cv.findChessboardCorners(greyFrameA, (8,6),flags = find_flags) \n",
    "            retB1, cornersB= cv.findChessboardCorners(greyFrameB, (8,6),flags = find_flags) \n",
    "            \n",
    "            if retA1 == True and retB1 == True:\n",
    "                objpoints.append(objp)\n",
    "     \n",
    "                corners2A = cv.cornerSubPix(greyFrameA,cornersA, (11,11), (-1,-1),criteria)\n",
    "                corners2B = cv.cornerSubPix(greyFrameB,cornersB, (11,11), (-1,-1),criteria)\n",
    "                imgpointsA.append(corners2A)\n",
    "                imgpointsB.append(corners2B)\n",
    "            \n",
    "                # Draw and display the corners  just for one frame\n",
    "                cv.drawChessboardCorners(frameA, (8,6), corners2A, retA1)\n",
    "                cv.drawChessboardCorners(frameB, (8,6), corners2B, retB1)\n",
    "                \n",
    "                frame_cat = cv.hconcat([frameA,frameB])\n",
    "                half = cv.resize(frame_cat, (0, 0), fx = 0.5, fy = 0.5)\n",
    "                cv.imshow('Frame', half)\n",
    "                if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    capA.release()\n",
    "    capB.release()\n",
    "    cv.destroyAllWindows()\n",
    "    ## Calibrate\n",
    "    retA, mtxA, distA, rvecsA, tvecsA = cv.calibrateCamera(objpoints, imgpointsA, greyFrameA.shape[::-1], None, None)\n",
    "    retB, mtxB, distB, rvecsB, tvecsB = cv.calibrateCamera(objpoints, imgpointsB, greyFrameB.shape[::-1], None, None)\n",
    "    \n",
    "    return objpoints,imgpointsA,greyFrameA, retA,mtxA,distA,imgpointsB,greyFrameB,retB,mtxB,distB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2e7af9-9ee5-4363-ad62-c34cc1c57c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Calibration\\Calib_video_3A.avi\n"
     ]
    }
   ],
   "source": [
    "# Video name\n",
    "Nvideo = '3'\n",
    "\n",
    "#VideoA = '.\\Calibration\\Example_video_5a.avi'\n",
    "#VideoB = '.\\Calibration\\Example_video_5b.avi'\n",
    "\n",
    "VideoA = '.\\Calibration\\Calib_video_'+Nvideo+'A.avi'\n",
    "VideoB = '.\\Calibration\\Calib_video_'+Nvideo+'B.avi'\n",
    "print(VideoA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c3913-c71e-4d55-919a-ae5d45fff01e",
   "metadata": {},
   "source": [
    "## 2. Detect corners of the chessboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a12a8a-e500-41a8-afb1-0276d8f83e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints,imgpointsA,greyFrameA, retA,mtxA,distA,imgpointsB,greyFrameB, retB,mtxB,distB = calibrate_both_cameras(VideoA,VideoB)\n",
    "len(imgpointsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24debeba-a9b4-448d-bc63-0ba584e8d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereocalibration_flags = cv.CALIB_FIX_INTRINSIC\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.0001)\n",
    "ret3D, CM1, dist1, CM2, dist2, R, T, E, F = cv.stereoCalibrate(objpoints, imgpointsA, imgpointsB, mtxA, distA,\n",
    "                                                                 mtxB, distB, greyFrameA.shape[::-1], criteria = criteria, flags = stereocalibration_flags)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378eaf97-a310-4fa8-8d96-82231e85dfc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(retA)\n",
    "print(retB)\n",
    "print(ret3D)\n",
    "#RT matrix for C1 is identity.\n",
    "RT1 = np.concatenate([np.eye(3), [[0],[0],[0]]], axis = -1)\n",
    "P1 = mtxA @ RT1 #projection matrix for C1\n",
    " \n",
    "#RT matrix for C2 is the R and T obtained from stereo calibration.\n",
    "RT2 = np.concatenate([R, T], axis = -1)\n",
    "P2 = mtxB @ RT2 #projection matrix for C2\n",
    "np.savez('.\\Calibration\\Calibration_parameters_'+Nvideo, ret3D=ret3D, CM1=CM1,dist1=dist1,CM2=CM2,dist2=dist2,R=R,T=T,E=E, F=F,P1 = P1, P2 = P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb4483-9dd4-4168-8136-f1811a8eba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nframes = len(imgpointsA)-1\n",
    "\n",
    "## plot last frame and the first point detected there\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(greyFrameA)\n",
    "ax1.plot(imgpointsA[Nframes][0][0][0],imgpointsA[Nframes][0][0][1],'.r')\n",
    "\n",
    "ax2.imshow(greyFrameB)\n",
    "ax2.plot(imgpointsB[Nframes][0][0][0],imgpointsB[Nframes][0][0][1],'.r')\n",
    "\n",
    "#print(imgpointsA[Nframes][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173922a-91d1-42fd-8f14-9348c57e32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "colours=['red','orange','yellow','lime','cyan','blue']\n",
    "\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(111, projection='3d')\n",
    "\n",
    "for iframes in np.arange(0,Nframes):\n",
    "    D3Points=[]\n",
    "    \n",
    "    for i in np.arange(0,8*6):\n",
    "        D3Point = DLT(P1,P2,imgpointsA[iframes][i][0], imgpointsB[iframes][i][0])\n",
    "        D3Points.append(D3Point)\n",
    "    if iframes == 0:\n",
    "        Maxs=np.max(D3Points,0)+10\n",
    "        Mins=np.min(D3Points,0)-10\n",
    "    \n",
    "    for i in np.arange(0,8*6-1): \n",
    "        row = int(np.floor(i/8))\n",
    "        ax.plot(D3Points[i][0], D3Points[i][1],D3Points[i][2],'.',color = colours[row])\n",
    "        ax.plot(xs=[D3Points[i][0],D3Points[i+1][0]], ys = [D3Points[i][1],D3Points[i+1][1]],zs = [D3Points[i][2],D3Points[i+1][2]],c = colours[row])\n",
    "    \n",
    "    \n",
    "    ax.set_xlim3d([Mins[0], Maxs[0]])\n",
    "    ax.set_ylim3d([Mins[1], Maxs[1]])\n",
    "    ax.set_zlim3d([Mins[2], Maxs[2]])\n",
    "    ax.view_init(-41, -67)    \n",
    "    plt.show()\n",
    "    plt.pause(0.01)\n",
    "    figname='.\\Calibration\\Fig_'+str(iframes)+'.png'\n",
    "    #plt.savefig(figname, bbox_inches='tight')\n",
    "    ax.cla()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2dea7-b037-42ed-ae45-018c6e51ad01",
   "metadata": {},
   "source": [
    "## Testing the calibration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec78aa8-1a8b-4b69-b82c-73370e2869e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628049f6-24c2-4ba5-a682-c6c0a652fd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
